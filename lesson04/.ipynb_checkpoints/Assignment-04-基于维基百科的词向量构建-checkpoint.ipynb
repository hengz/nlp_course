{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-04 基于维基百科的词向量构建\n",
    "\n",
    "在本章，你将使用Gensim和维基百科获得你的第一批词向量，并且感受词向量的基本过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-01: Download Wikipedia Chinese Corpus\n",
    "\n",
    "第一步：使用维基百科下载中文语料库\n",
    "\n",
    "https://dumps.wikimedia.org/zhwiki/20190720/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T15:26:48.029700Z",
     "start_time": "2019-07-28T15:26:48.025673Z"
    }
   },
   "source": [
    "## Step-02: Using wikiextractor to extract the wikipedia corpus\n",
    "\n",
    "第二步：使用python wikipedia extractor抽取维基百科的内容\n",
    "\n",
    "https://github.com/attardi/wikiextractor\n",
    "\n",
    "执行：\n",
    "\n",
    "```shell\n",
    "> python WikiExtractor.py -o .\\output D:\\BaiduYunDownload\\维基百科中文20190720\\zhwiki-20190720-pages-articles-multistream.xml.bz2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step-03: Using gensim get word vectors:\n",
    "Reference:\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne\n",
    "\n",
    "第三步：参考Gensim的文档和Kaggle的参考文档，获得词向量。 注意，你要使用Jieba分词把维基百科的内容切分成一个一个单词，然后存进新的文件中。然后，你需要用Gensim的LineSentence这个类进行文件的读取。\n",
    "\n",
    "在训练成词向量Model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cut words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T10:29:22.229032Z",
     "start_time": "2019-08-15T10:29:22.225031Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import jieba.analyse\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.word2vec import PathLineSentences\n",
    "\n",
    "\n",
    "corpus_path = 'E:\\\\GitHub\\\\wikiextractor\\\\output' #source corpus path\n",
    "sentences_path = 'E:\\\\corpus' #words corpus path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T08:26:05.901271Z",
     "start_time": "2019-08-15T08:26:05.896275Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_files(root_path):\n",
    "    \"\"\"\n",
    "    return all file pathes as a list under one directory\n",
    "    \"\"\"\n",
    "    pathes = []\n",
    "    for root, dirs, files in os.walk(corpus_path):\n",
    "        if not files:\n",
    "            continue\n",
    "        for file in files:\n",
    "            pathes.append(root + '\\\\' + file)\n",
    "    return pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T08:49:57.546060Z",
     "start_time": "2019-08-15T08:49:47.025133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "e:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    preprocess text, drop number, blank, stopwords\n",
    "    return segments list\n",
    "    \"\"\"\n",
    "    stopwords=pd.read_csv('.\\\\stopwords.txt',index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "    stopwords=stopwords['stopword'].values\n",
    "    \n",
    "    try:\n",
    "        segs = list(jieba.cut(text))\n",
    "        segs = [v for v in segs if not str(v).isdigit()]#去数字\n",
    "        segs = list(filter(lambda x:x.strip(), segs)) #去左右空格\n",
    "        segs = list(filter(lambda x:len(x)>1, segs))#长度为1的字符\n",
    "        segs = list(filter(lambda x:x not in stopwords, segs)) #去掉停用词\n",
    "    except Exception:\n",
    "        print(Exception)\n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T10:31:04.687128Z",
     "start_time": "2019-08-15T10:29:51.337397Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "generate new files after cutting words\n",
    "\"\"\"\n",
    "file_pathes = get_all_files(corpus_path)\n",
    "\n",
    "limit = 10000\n",
    "i = 0\n",
    "\n",
    "for file_path in file_pathes:\n",
    "    with open(file_path, 'r', encoding='utf-8') as rf:\n",
    "        with open(sentences_path+'\\\\'+str(i)+'.txt', 'w+', encoding='utf-8') as wf:\n",
    "            for line in rf.readlines():\n",
    "                if line == '\\n':\n",
    "                    continue\n",
    "                if line[0] == '<':\n",
    "                    continue\n",
    "                i += 1\n",
    "                segs = preprocess_text(line)\n",
    "                wf.write(' '.join(segs))\n",
    "    if i > limit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T10:33:00.399951Z",
     "start_time": "2019-08-15T10:32:48.144903Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "sentences = PathLineSentences(sentences_path, limit=1)\n",
    "\n",
    "'''\n",
    "LineSentence(inp)：格式简单：一句话=一行; 单词已经过预处理并被空格分隔。\n",
    "size：是每个词的向量维度； \n",
    "window：是词向量训练时的上下文扫描窗口大小，窗口为5就是考虑前5个词和后5个词； \n",
    "min-count：设置最低频率，默认是5，如果一个词语在文档中出现的次数小于5，那么就会丢弃； \n",
    "workers：是训练的进程数（需要更精准的解释，请指正），默认是当前运行机器的处理器核数。这些参数先记住就可以了。\n",
    "sg ({0, 1}, optional) – 模型的训练算法: 1: skip-gram; 0: CBOW\n",
    "alpha (float, optional) – 初始学习率\n",
    "iter (int, optional) – 迭代次数，默认为5\n",
    "'''\n",
    "model = Word2Vec(sentences=sentences, size=100, window=5, min_count=1, sg=1)\n",
    "\n",
    "model.save(\".\\\\word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-04: Using some words to test your preformance.\n",
    "\n",
    "第四步，测试同义词，找几个单词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T10:35:26.520780Z",
     "start_time": "2019-08-15T10:35:26.516781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32242677  0.12971713  0.2020709   0.3632374   0.9222486  -0.55811554\n",
      " -0.28390476  0.28367355  0.1964107  -0.21977392 -0.06444634  0.16362631\n",
      "  0.03197181  0.19361655 -0.16852972 -0.01497601  0.87039506 -0.28291765\n",
      " -0.06348117  0.3588286  -0.6118939  -0.2945417  -0.46971563 -0.5631982\n",
      "  0.34107518 -0.08078215 -1.232944    0.1503928  -0.06569257  0.07252707\n",
      " -0.8946868   0.5967637   0.5617484   0.36433455 -0.05487395  0.6541698\n",
      " -0.13211599 -0.33732408  0.31179795  0.32845244  0.11792107 -0.3170439\n",
      " -0.19777887 -0.57849216 -0.15530036  0.445071   -0.23603877 -0.14478168\n",
      " -0.3815146   0.8960201   0.298135    0.09621727  0.4851041   0.03529807\n",
      " -0.92373455  0.14742832 -0.02569527 -0.21468323  0.3877639  -0.2643373\n",
      " -0.19145395 -0.49811006 -0.2772722   0.16501157 -0.17221622 -0.5216831\n",
      " -0.05388469  0.6187258  -0.41403374  0.14545973 -0.5051723   0.19265892\n",
      " -0.6928579   0.2558732  -0.41839534 -0.7749304   0.08568496 -0.5544341\n",
      " -0.5532263   0.22697765 -0.42497575  0.23071884  0.12475619  0.6452243\n",
      "  0.14030631 -0.39743355 -0.14736338 -0.15135099  0.4152698   0.90936416\n",
      "  0.27476084 -0.53434634  0.0046386  -0.32621342 -0.04737615 -0.34212917\n",
      " -0.50128776 -0.0820208   0.68639815 -0.0733432 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model['中国'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T10:36:18.238241Z",
     "start_time": "2019-08-15T10:36:18.233258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5007452   0.10219055 -0.32905862  0.11369596  0.7433472  -0.04048169\n",
      " -0.40990755  0.22003876  0.02057978 -0.42945328 -0.16393243 -0.18261424\n",
      " -0.22520319  0.14518121 -0.0525115  -0.11810838  0.41022584 -0.14147696\n",
      "  0.31358632  0.3409524  -0.4367431   0.4189133  -0.04084573 -0.6241634\n",
      "  0.07543996 -0.06181612 -0.8216611   0.30633673 -0.07451538  0.2397082\n",
      " -0.32713944  0.15042588  0.37081626  0.11423954  0.15377311  0.35698316\n",
      "  0.03006061  0.02773372  0.4609735   0.10990081  0.07908319 -0.16551732\n",
      "  0.18416736 -0.23363319 -0.48199022  0.00179261  0.30570132 -0.28700334\n",
      " -0.14028281  0.47954333 -0.06488842 -0.11705579  0.15717424 -0.00782508\n",
      " -0.49156383  0.18056244  0.31305757  0.00255206  0.21876153 -0.18654749\n",
      "  0.20955521 -0.41260055 -0.34611264  0.25265303 -0.00279441 -0.3569383\n",
      " -0.25085923  0.20668027 -0.17850289  0.04928784 -0.51274717 -0.04985979\n",
      " -0.3842528   0.20844556 -0.30001938 -0.5342532   0.1900018   0.08399962\n",
      " -0.5444809   0.5911435  -0.08231807  0.07196554  0.18590876  0.22780718\n",
      " -0.4006058  -0.13825744 -0.03085083  0.14154686  0.5631382   0.48961255\n",
      " -0.01564805 -0.02863442  0.06863475 -0.36299592 -0.08014347 -0.08736015\n",
      " -0.39189178 -0.19326219  0.30932078  0.32404032]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model['北京'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T10:36:21.167607Z",
     "start_time": "2019-08-15T10:36:21.163611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18818612  0.05914191 -0.46481448 -0.09066724  0.39920747  0.38367796\n",
      " -0.722312    0.05082085  0.07305121 -0.41403073 -0.20223632 -0.13346133\n",
      " -0.3583985  -0.05723323  0.04368744  0.24109672  0.13027646 -0.11257724\n",
      "  0.13885616  0.14313225 -0.23422834  0.18115498  0.28590676 -0.19023846\n",
      " -0.03333521 -0.010207   -0.82052076  0.46401957  0.10739937  0.26979136\n",
      " -0.1804987   0.5027365   0.46676564  0.13664642  0.28820288  0.23880954\n",
      "  0.16560265 -0.12516342  0.585944   -0.14872144  0.11497646 -0.30897352\n",
      "  0.04645425  0.05566444 -0.4432086  -0.14166217  0.33963412 -0.1946155\n",
      " -0.24318226  0.8164626  -0.16104457 -0.34987578  0.09355684 -0.20611012\n",
      " -0.19640651  0.18445201  0.18920024  0.08458568  0.1703575  -0.40404052\n",
      "  0.2120697  -0.47506446 -0.46961927  0.44609952  0.35195532 -0.41860363\n",
      "  0.10224506 -0.01112052  0.38819352  0.1411015  -0.41493973 -0.35139906\n",
      " -0.24966563 -0.00126147 -0.57345897 -0.57567614 -0.08771753  0.4757634\n",
      " -0.3937756   0.341965   -0.1304231  -0.17436333  0.00364188  0.00419292\n",
      " -0.13729072 -0.12626602 -0.12117905 -0.05063468  0.27745464  0.58644986\n",
      " -0.19087243  0.14960341  0.14974833 -0.31608865 -0.17212585 -0.0214435\n",
      " -0.17359988 -0.25366127  0.37521973  0.23418349]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model['袁世凯'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-05: Using visualization tools\n",
    "\n",
    "https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne\n",
    "\n",
    "第五步：使用Kaggle给出的T-SEN进行词向量的可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T10:39:21.821280Z",
     "start_time": "2019-08-15T10:39:03.668464Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "e:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "e:\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T10:37:53.128944Z",
     "start_time": "2019-08-15T10:37:53.111953Z"
    }
   },
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
